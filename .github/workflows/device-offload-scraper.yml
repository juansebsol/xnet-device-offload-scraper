name: Device Offload Scraper

on:
  # Manual trigger with inputs
  workflow_dispatch:
    inputs:
      nas_id:
        description: 'NAS ID to scrape'
        required: true
        type: string
        default: 'bcb92300ae0c'
      start_date:
        description: 'Start date (YYYY-MM-DD) - optional'
        required: false
        type: string
      end_date:
        description: 'End date (YYYY-MM-DD) - optional'
        required: false
        type: string
      force_refresh:
        description: 'Force refresh existing data'
        required: false
        type: boolean
        default: false
  
  # Repository dispatch (can be triggered by external API calls)
  repository_dispatch:
    types: [device-offload-scrape]

jobs:
  scrape-device-offload:
    runs-on: ubuntu-latest
    
    steps:
    - name: 🚀 Checkout code
      uses: actions/checkout@v4
      
    - name: 📦 Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        
    - name: 🔧 Install dependencies
      run: npm ci
      
    - name: 🎯 Set up environment
      run: |
        echo "OKTA_START_URL=${{ secrets.OKTA_START_URL }}" >> $GITHUB_ENV
        echo "OKTA_EMAIL=${{ secrets.OKTA_EMAIL }}" >> $GITHUB_ENV
        echo "OKTA_PASSWORD=${{ secrets.OKTA_PASSWORD }}" >> $GITHUB_ENV
        echo "SUPABASE_URL=${{ secrets.SUPABASE_URL }}" >> $GITHUB_ENV
        echo "SUPABASE_SERVICE_ROLE_KEY=${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}" >> $GITHUB_ENV
        
    - name: 🎭 Install Playwright browsers
      run: npx playwright install --with-deps chromium
      
    - name: 🔍 Determine scraping parameters
      id: params
      run: |
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          echo "nas_id=${{ github.event.inputs.nas_id }}" >> $GITHUB_OUTPUT
          echo "start_date=${{ github.event.inputs.start_date }}" >> $GITHUB_OUTPUT
          echo "end_date=${{ github.event.inputs.end_date }}" >> $GITHUB_OUTPUT
        elif [ "${{ github.event_name }}" = "repository_dispatch" ]; then
          echo "nas_id=${{ github.event.client_payload.nas_id }}" >> $GITHUB_OUTPUT
          echo "start_date=${{ github.event.client_payload.start_date }}" >> $GITHUB_OUTPUT
          echo "end_date=${{ github.event.client_payload.end_date }}" >> $GITHUB_OUTPUT
        else
          echo "nas_id=bcb92300ae0c" >> $GITHUB_OUTPUT
          echo "start_date=" >> $GITHUB_OUTPUT
          echo "end_date=" >> $GITHUB_OUTPUT
        fi
        
    - name: 🚀 Run device offload scraper
      run: |
        echo "🎯 Scraping device offload data for NAS ID: ${{ steps.params.outputs.nas_id }}"
        START_DATE="${{ steps.params.outputs.start_date }}"
        END_DATE="${{ steps.params.outputs.end_date }}"
        NAS_ID="${{ steps.params.outputs.nas_id }}"
        
        echo "DEBUG: START_DATE='$START_DATE'"
        echo "DEBUG: END_DATE='$END_DATE'"
        
        if [ -n "$START_DATE" ] && [ -n "$END_DATE" ] && [ "$START_DATE" != "" ] && [ "$END_DATE" != "" ]; then
          echo "📅 Using custom date range: $START_DATE to $END_DATE"
          node src/scrapeDeviceOffload.js "$NAS_ID" "$START_DATE" "$END_DATE"
        else
          echo "📅 Using default date range"
          node src/scrapeDeviceOffload.js "$NAS_ID"
        fi
        
    - name: 📊 Parse and validate CSV
      id: parse-csv
      run: |
        echo "📋 Parsing downloaded CSV file..."
        LATEST_FILE=$(ls -t downloads/*.txt downloads/*.csv 2>/dev/null | head -1)
        if [ -z "$LATEST_FILE" ]; then
          echo "❌ No downloaded file found"
          exit 1
        fi
        
        echo "📁 Processing file: $LATEST_FILE"
        PARSE_RESULT=$(node src/parseDeviceCsv.js "$LATEST_FILE")
        echo "parse_result<<EOF" >> $GITHUB_OUTPUT
        echo "$PARSE_RESULT" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT
        
    - name: 💾 Upload data to database
      run: |
        echo "💾 Upserting data to database..."
        LATEST_FILE=$(ls -t downloads/*.txt downloads/*.csv 2>/dev/null | head -1)
        
        if [ -z "$LATEST_FILE" ]; then
          echo "❌ No downloaded file found for upsert"
          exit 1
        fi
        
        echo "📁 Processing file: $LATEST_FILE"
        
        # Parse the CSV and get the data
        echo "📊 Parsing CSV for upsert..."
        PARSE_RESULT=$(node src/parseDeviceCsv.js "$LATEST_FILE")
        
        # Call upsert with the correct arguments: (deviceData, nasId, sourceFilename)
        # We need to pass the parsed data, not just the filename
        echo "🔄 Calling upsert with parsed data..."
        node -e "
          const { parseDeviceCsv } = require('./src/parseDeviceCsv.js');
          const { upsertDeviceOffload } = require('./src/upsertDeviceOffload.js');
          const fs = require('fs');
          
          const fileContent = fs.readFileSync('$LATEST_FILE', 'utf8');
          const parseResult = parseDeviceCsv(fileContent);
          
          if (parseResult.data && parseResult.data.length > 0) {
            console.log('📊 Parsed data ready for upsert');
            upsertDeviceOffload(parseResult.data, '${{ steps.params.outputs.nas_id }}', '$LATEST_FILE')
              .then(result => {
                console.log('✅ Upsert completed:', result);
                process.exit(0);
              })
              .catch(error => {
                console.error('❌ Upsert failed:', error);
                process.exit(1);
              });
          } else {
            console.error('❌ No valid data parsed from CSV');
            process.exit(1);
          }
        "
        
    - name: 📋 Upload artifacts
      uses: actions/upload-artifact@v4
      with:
        name: device-offload-data-${{ steps.params.outputs.nas_id }}-${{ github.run_id }}
        path: |
          downloads/
        retention-days: 7
        
    - name: 📊 Summary
      run: |
        echo "🎉 Device offload scraping completed successfully!"
        echo "🎯 NAS ID: ${{ steps.params.outputs.nas_id }}"
        if [ -n "${{ steps.params.outputs.start_date }}" ] && [ -n "${{ steps.params.outputs.end_date }}" ]; then
          echo "📅 Date Range: ${{ steps.params.outputs.start_date }} to ${{ steps.params.outputs.end_date }}"
        else
          echo "📅 Date Range: Default (last 7 days)"
        fi
        echo "📁 Artifacts uploaded"
        echo "⏰ Completed at: $(date)"
        
  # Optional: Add a job to notify external systems
  notify-completion:
    needs: scrape-device-offload
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: 📢 Notify completion
      run: |
        if [ "${{ needs.scrape-device-offload.result }}" = "success" ]; then
          echo "✅ Scraping completed successfully"
          # Add webhook notifications here if needed
        else
          echo "❌ Scraping failed"
          # Add failure notifications here if needed
        fi
